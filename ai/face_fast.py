# -*- coding: utf-8 -*-
"""show_name.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14mD0WHrLAZZMQdqf3Qt3JTcBwTglHVu8
"""

# !pip install face_recognition

import sys
import face_recognition
import cv2
import numpy as np
from PIL import ImageFont, ImageDraw, Image
import glob

import config
threshold = config.threshold

face_locations = []
face_encodings = []

#image_paths = glob.glob("../img/*")
image_paths = glob.glob("../img_jp/*")
image_paths.sort()
known_face_encodings = []
known_face_names = []
checked_face = []

delimiter = "\\"

for image_path in image_paths:
  im_name = image_path.split(delimiter)[-1].split('.')[0]
  image = face_recognition.load_image_file(image_path)
  face_encoding = face_recognition.face_encodings(image)[0]
  known_face_encodings.append(face_encoding)
  known_face_names.append(im_name)



video_catpture = cv2.VideoCapture(0)

def main():
  # 処理フラグの初期化
  process_this_frame = True

  while True:
    # ビデオの単一フレームを取得
    _, frame = video_catpture.read()

    # 時間を節約するために、フレーム毎に処理をスキップ
    if prpcess_this_frame:
      small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)

    # 顔の位置情報を検索
    face_locations = face_recognition.face_locations(small_frame)
    # 顔の位置情報の符号化
    face_encodings = face_recognition.face_encodings(small_frame, face_locations)

    for face_encoding in face_encodings:
      matches = face_recognition.compare_faces(known_face_encodings, face_encoding, threshold)
      name = "Unkonwn"

      #　顔画像と最も近い登録画像を候補とする
      face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
      best_match_index = np.argmin(face_distances)
      if matches[best_match_index]:
        name = known_face_names[best_match_index]
    
    #　処理フラグの切り替え
      process_this_frame = not.process_this_frame

    # 位置情報の表示
    for (top, right, bottom, left) in face_locations:
      
      # 圧縮した画像の座標を復元
      top *= 4
      right *= 4
      left *= 4
      bottom *= 4


      # 顔領域を描画
      cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)

      # 顔領域の下に枠を表示
      cv2.rectangle(frame, (left, bottom -35), (right, bottom), (0, 0, 255), cv2.FILLED)
      #font = cv2.FONT_HERSHEY_DUPLEX
      #cv2.putText(frame, name, (left + 6, bottom -6), font, 1.0, (255, 255, 255), 1)

      # 日本語表示
      font_path = 'meiryo.ttc'
      font = ImageFont.truetype(font_path, 32)
      img_pl = Image.fromarray(frame)
      draw = ImageDraw.Draw(img_pl)
      position = (left + 6, bottom + -40)
      # drawにテキストを配置
      draw.text(position, name, font=font, fill=(255, 255, 255, 0))
      frame = np.array(img_pl)

      

    # 結果をビデオで表示
    cv2.imshow("Video", frame)

    # ESCキーで終了
    if cv2.waitKey(1) == 27:
      break

main()

video_catpture.release()
cv2.destroyAllWindows()